@PREAMBLE{
 "\providecommand{\noopsort}[1]{}" 
 # "\providecommand{\singleletter}[1]{#1}%" 
}

@article{grabovoi2024unraveling748584228,
    author = {Kiselev, N. S. and Grabovoy, A. V.},
    title = {Unraveling the Hessian: A Key to Smooth Convergence in Loss Function Landscapes},
    journal = {Doklady Mathematics},
    year = {2024},
    volume = {110},
    number = {S1},
    issn = {1064-5624; 1531-8362},
    doi = {10.1134/s1064562424601987},
    pages = {S49--S61},
    publisher = {Maik Nauka/Interperiodica Publishing},
    address = {Russian Federation},
    language = {english}
}

@inproceedings{grabovoi2024convnets743111032,
    author = {Meshkov, Vladislav and Kiselev, Nikita and Grabovoy, Andrey},
    title = {ConvNets Landscape Convergence: Hessian-Based Analysis of Matricized Networks},
    booktitle = {2024 Ivannikov Ispras Open Conference (ISPRAS)},
    year = {2024},
    doi = {10.1109/ispras64596.2024.10899113},
    pages = {1--10},
    address = {IEEE},
    language = {english}
}

@misc{sagun2018empiricalanalysishessianoverparametrized,
    title={Empirical Analysis of the Hessian of Over-Parametrized Neural Networks}, 
    author={Levent Sagun and Utku Evci and V. Ugur Guney and Yann Dauphin and Leon Bottou},
    year={2018},
    eprint={1706.04454},
    archivePrefix={arXiv},
    primaryClass={cs.LG},
    url={https://arxiv.org/abs/1706.04454}, 
}

@misc{skorski2019chainruleshessianhigher,
    title={Chain Rules for Hessian and Higher Derivatives Made Easy by Tensor Calculus}, 
    author={Maciej Skorski},
    year={2019},
    eprint={1911.13292},
    archivePrefix={arXiv},
    primaryClass={cs.SC},
    url={https://arxiv.org/abs/1911.13292}, 
}

@InProceedings{pmlr-v97-ghorbani19b,
    title = 	 {An Investigation into Neural Net Optimization via Hessian Eigenvalue Density},
    author =       {Ghorbani, Behrooz and Krishnan, Shankar and Xiao, Ying},
    booktitle = 	 {Proceedings of the 36th International Conference on Machine Learning},
    pages = 	 {2232--2241},
    year = 	 {2019},
    editor = 	 {Chaudhuri, Kamalika and Salakhutdinov, Ruslan},
    volume = 	 {97},
    series = 	 {Proceedings of Machine Learning Research},
    month = 	 {09--15 Jun},
    publisher =    {PMLR},
    pdf = 	 {http://proceedings.mlr.press/v97/ghorbani19b/ghorbani19b.pdf},
    url = 	 {https://proceedings.mlr.press/v97/ghorbani19b.html}
}

@misc{papyan2019spectrumdeepnethessiansscale,
    title={The Full Spectrum of Deepnet Hessians at Scale: Dynamics with SGD Training and Sample Size}, 
    author={Vardan Papyan},
    year={2019},
    eprint={1811.07062},
    archivePrefix={arXiv},
    primaryClass={cs.LG},
    url={https://arxiv.org/abs/1811.07062}, 
}

@article{keskar2016large,
    title={On Large-Batch Training for Deep Learning: Generalization Gap and Sharp Minima},
    author={Nitish Shirish Keskar and Dheevatsa Mudigere and Jorge Nocedal and Mikhail Smelyanskiy and Ping Tak Peter Tang},
    journal={ArXiv},
    year={2016},
    volume={abs/1609.04836},
    url={https://api.semanticscholar.org/CorpusID:5834589}
}

@inproceedings{dinh2017sharp,
    title={Sharp Minima Can Generalize For Deep Nets},
    author={Laurent Dinh and Razvan Pascanu and Samy Bengio and Yoshua Bengio},
    booktitle={International Conference on Machine Learning},
    year={2017},
    url={https://api.semanticscholar.org/CorpusID:7636159}
}

@inproceedings{li2018visualizing,
    author = {Li, Hao and Xu, Zheng and Taylor, Gavin and Studer, Christoph and Goldstein, Tom},
    booktitle = {Advances in Neural Information Processing Systems},
    editor = {S. Bengio and H. Wallach and H. Larochelle and K. Grauman and N. Cesa-Bianchi and R. Garnett},
    pages = {},
    publisher = {Curran Associates, Inc.},
    title = {Visualizing the Loss Landscape of Neural Nets},
    url = {https://proceedings.neurips.cc/paper_files/paper/2018/file/a41b3bb3e6b050b6c9067c67f663b915-Paper.pdf},
    volume = {31},
    year = {2018}
}

@inproceedings{singh2023hessianperspectivenatureconvolutional,
    author = {Singh, Sidak Pal and Hofmann, Thomas and Sch\"{o}lkopf, Bernhard},
    title = {The Hessian perspective into the nature of convolutional neural networks},
    year = {2023},
    publisher = {JMLR.org},
    booktitle = {Proceedings of the 40th International Conference on Machine Learning},
    articleno = {1324},
    numpages = {39},
    location = {Honolulu, Hawaii, USA},
    series = {ICML'23}
}

@article{ormaniec2024attentionhessian,
    title   = {What Does It Mean to Be a Transformer? Insights from a Theoretical Hessian Analysis},
    author  = {Weronika Ormaniec and Felix Dangel and Sidak Pal Singh},
    year    = {2024},
    journal = {arXiv preprint arXiv:2410.10986},
    note    = {Self-Attention Block decomposition}
}

@article{pearlmutter1994fast,
    title={Fast exact multiplication by the Hessian},
    author={Pearlmutter, Barak A},
    journal={Neural computation},
    volume={6},
    number={1},
    pages={147--160},
    year={1994},
    publisher={MIT Press}
}

@inproceedings{yao2020pyhessian,
    title={Pyhessian: Neural networks through the lens of the hessian},
    author={Yao, Zhewei and Gholami, Amir and Keutzer, Kurt and Mahoney, Michael W},
    booktitle={2020 IEEE international conference on big data (Big data)},
    pages={581--590},
    year={2020},
    organization={IEEE}
}

@inproceedings{pennington2017spectrum,
    author = {Pennington, Jeffrey and Worah, Pratik},
    booktitle = {Advances in Neural Information Processing Systems},
    editor = {S. Bengio and H. Wallach and H. Larochelle and K. Grauman and N. Cesa-Bianchi and R. Garnett},
    pages = {},
    publisher = {Curran Associates, Inc.},
    title = {The Spectrum of the Fisher Information Matrix of a Single-Hidden-Layer Neural Network},
    url = {https://proceedings.neurips.cc/paper_files/paper/2018/file/18bb68e2b38e4a8ce7cf4f6b2625768c-Paper.pdf},
    volume = {31},
    year = {2018}
}

@article{pennington2018emergence,
  title={The Emergence of Spectral Universality in Deep Networks},
  author={Jeffrey Pennington and Samuel S. Schoenholz and Surya Ganguli},
  journal={ArXiv},
  year={2018},
  volume={abs/1802.09979},
  url={https://api.semanticscholar.org/CorpusID:3569532}
}

@InProceedings{gurari2018gradient,
    title = 	 {Gradient Descent Finds Global Minima of Deep Neural Networks},
    author =       {Du, Simon and Lee, Jason and Li, Haochuan and Wang, Liwei and Zhai, Xiyu},
    booktitle = 	 {Proceedings of the 36th International Conference on Machine Learning},
    pages = 	 {1675--1685},
    year = 	 {2019},
    editor = 	 {Chaudhuri, Kamalika and Salakhutdinov, Ruslan},
    volume = 	 {97},
    series = 	 {Proceedings of Machine Learning Research},
    month = 	 {09--15 Jun},
    publisher =    {PMLR},
    pdf = 	 {http://proceedings.mlr.press/v97/du19c/du19c.pdf},
    url = 	 {https://proceedings.mlr.press/v97/du19c.html}
}

@article{chaudhari2016entropy,
    title={Entropy-SGD: biasing gradient descent into wide valleys},
    author={Pratik Chaudhari and Anna Choromańska and Stefano Soatto and Yann LeCun and Carlo Baldassi and Christian Borgs and Jennifer Tour Chayes and Levent Sagun and Riccardo Zecchina},
    journal={Journal of Statistical Mechanics: Theory and Experiment},
    year={2016},
    volume={2019},
    url={https://api.semanticscholar.org/CorpusID:13807351}
}

@inproceedings{fort2019large,
 author = {Fort, Stanislav and Jastrzebski, Stanislaw},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {H. Wallach and H. Larochelle and A. Beygelzimer and F. d\textquotesingle Alch\'{e}-Buc and E. Fox and R. Garnett},
 pages = {},
 publisher = {Curran Associates, Inc.},
 title = {Large Scale Structure of Neural Network Loss Landscapes},
 url = {https://proceedings.neurips.cc/paper_files/paper/2019/file/48042b1dae4950fef2bd2aafa0b971a1-Paper.pdf},
 volume = {32},
 year = {2019}
}

@article{fort2019energy,
  title={The Goldilocks zone: Towards better understanding of neural network loss landscapes},
  author={Stanislav Fort and Adam Scherlis},
  journal={ArXiv},
  year={2018},
  volume={abs/1807.02581},
  url={https://api.semanticscholar.org/CorpusID:49655834}
}

@article{kaplan2020ScalingLaws,
    author       = {Jared Kaplan and
                  Sam McCandlish and
                  Tom Henighan and
                  Tom B. Brown and
                  Benjamin Chess and
                  Rewon Child and
                  Scott Gray and
                  Alec Radford and
                  Jeffrey Wu and
                  Dario Amodei},
    title        = {Scaling Laws for Neural Language Models},
    journal      = {CoRR},
    volume       = {abs/2001.08361},
    year         = {2020},
    url          = {https://arxiv.org/abs/2001.08361},
    eprinttype    = {arXiv},
    eprint       = {2001.08361}
}

@inproceedings{hoffmann2022Chinchila,
    author = {Hoffmann, Jordan and Borgeaud, Sebastian and Mensch, Arthur and Buchatskaya, Elena and Cai, Trevor and Rutherford, Eliza and de Las Casas, Diego and Hendricks, Lisa Anne and Welbl, Johannes and Clark, Aidan and Hennigan, Tom and Noland, Eric and Millican, Katie and van den Driessche, George and Damoc, Bogdan and Guy, Aurelia and Osindero, Simon and Simonyan, Karen and Elsen, Erich and Vinyals, Oriol and Rae, Jack W. and Sifre, Laurent},
    title = {Training compute-optimal large language models},
    year = {2022},
    isbn = {9781713871088},
    publisher = {Curran Associates Inc.},
    address = {Red Hook, NY, USA},
    booktitle = {Proceedings of the 36th International Conference on Neural Information Processing Systems},
    articleno = {2176},
    numpages = {15},
    location = {New Orleans, LA, USA},
    series = {NIPS '22}
}

@article{mcallester2013book,
  title={A PAC-Bayesian Tutorial with A Dropout Bound},
  author={David A. McAllester},
  journal={ArXiv},
  year={2013},
  volume={abs/1307.2118},
  url={https://api.semanticscholar.org/CorpusID:1936248}
}

@inproceedings{NEURIPS2018_5a4be1fa,
	author = {Jacot, Arthur and Gabriel, Franck and Hongler, Clement},
	booktitle = {Advances in Neural Information Processing Systems},
	title = {Neural Tangent Kernel: Convergence and Generalization in Neural Networks},
	volume = {31},
	year = {2018}
}

@phdthesis{vorontsov2010doctoral,
    author = {Воронцов, Константин Вячеславович},
    title = {Комбинаторная теория надежности обучения по прецедентам},
    school = {МГУ},
    year = {2010},
    url = {http://www.machinelearning.ru/wiki/images/b/b6/Voron10doct.pdf},
    language = {russian}
}